Implementation
==============
This sections goes into detail about the algorithms and data used
by detcap.

Channel selection and inventory
-------------------------------
The first step of the processing pipeline is to sort out the stations
and channels being used.

Detcap works by fetching every station possible from the inventory
(either provided by the user or taken from an FDSN server). The stations
considered are based on:

- filtering provided by the user (excluding/including station and/or
  network codes)
- some base filtering that excludes e.g. metadata channels
- the channel properties required by the magnitude metric
- whether required metadata is available in the inventory

For user filtering, see :ref:`station-filtering`.

The base filtering is part of the :py:mod:`detcap.settings` module.
Currently this only allows channels matching: [B|H|S] [H|L] [Z|N|E|1|2].
In English: only broadband, high broadband, short period bands,
high gain, low gain seismometers and north, south, east, west and
vertical oriented channels are considered.

The channel properties is an interal mechanism ensuring we only
calculate on the channels compatible with the magnitude. For both
mla and mb, this restricts the channels used to vertical orientation.

The metadata required from the inventory:

- A velocity (m/s) PAZ response, including gain and sensitivity
- A latitude and longitude (the coordinate is taken from the station
  and used for all channels)
- A sample rate

Channels missing any of this metadata are not considered.

Data acquisition
----------------
We can then proceed to start receiving data via Seedlink for each
used channel.

When a waveform arrives (I use the term "packet" and "trace" interchangably
from here on to refer to a block of data received from Seedlink), the
arrival time is recorded and the packet data is stored.

This continues until an update is triggered, currently hardcoded
to every 60 seconds.

Trace processing
----------------

When the update is triggered, the collected packets are "handled". 
This involves taking a 20 second window of data, starting from the time
of the last update, so the time window covers:

.. math::
    
    (now - 60s)\ to\ (now - 40s)

I refer to this time window as the "long-term average" or LTA. As in,
we are performing our calculations on a long-term average of 20 seconds
of station data.

This 20 second slice is taken for each channel.

Latency
~~~~~~~
For latency measurements, we subtract the arrival time of each packet
(when we got it) from the start time of the packet's measuring window.

.. figure:: _static/latency_diagram.png
    :align: center
    
    Visual representation of latency calculation.

We store these values for later processing. This measurement accounts
for both network latency, and the length of the measuring window
(assuming a worst case scenario of a meaningful signal occurring at
the end of a measurement).

This accounts for backfilled packets by increasing the overall latecy.
E.g. if a packet was recorded 10 minutes ago but we're only seeing it now,
then 10 minutes + the length of the measurement window is added to that
channel's collection of latency measurements.

Amplitude
~~~~~~~~~
For each trace, we simulate it as being observed on either a Wood-Anderson
seismometer (for mla) or a World-Wide Standardized Seismograph Network
Short-Period (WWSSN SP) seismometer (for mb). We store the simulated
trace values for later processing. Both types of amplitude are output
as displacement in meters.

Simulation of mla amplitude
~~~~~~~~~~~~~~~~~~~~~~~~~~~
For mla, the seismometer simulation comes from the accepeted method
of processing amplitudes for local magnitudes. This can be found written
by IASPEI [1]_ under "Standard Procedures for Widely Used Magnitude Types".

It also follows SeisComP's method: we can see in our custom mla plugin [2]_
that we use Seiscomp's MLv amplitude processor [3]_ to calculate mla
amplitude. The MLv processor itself is a wrapper around the
ML amplitude processor [4]_, which simulates the amplitude as Wood-Anderson.

.. note::

    I'm unsure about the correction required for calculating ML amplitude
    on a vertical component. The IASPEI paper specifies 
    `ML = log10(A) + C(R) + D`, where `C(R)` and `D` 
    "have been calibrated... to adjust... between amplitudes measured on
    horizontal seismographs and thsoe measured on vertical seismographs"

    The calibration term for the regional difference is handled by
    the MLa formula, but I haven't considered the horizontal to vertical
    calibration. SeisComP handles this by multiplying the result
    of the ML amplitude by 2. I should implement this solely because
    it's what SeisComP does.

The poles and zeros used for Wood-Anderson:

    - Poles: [-6.283 + 4.7124j, -6.283 + -4.7124]
    - Zeros: [0 + 0j]
    - Gain: 1.0
    - Sensitivity: 2080

These values come from Obspy [5]_. These differ from those used by IASPEI [1]_
and SeisComP [6]_. Because Obspy has a documented interface with examples
of doing this simulation, I ended up using these values.

.. note::

   This is something I could use help on. In the IASPEI paper,
   along with the poles and zeros they also specify "seismometer free period",
   and "seismometer damping constant". I don't know how these factor into
   the simulation, and aren't used by Obspy. Obspy also uses gain and sensitivity,
   which IASPEI doesn't specify. Alternatives to processing are to implement
   SeisComP's method or use something like SAC. So in general I'm sort of
   lost when it comes to performing these simulations.

The simulation is done using Obspy's ``simulate_seismometer`` [7]_.
Before simulation, the trace is detrended and run through a 0.2-7Hz 3-corner
bandpass filter. We then perform the simulation with a ``water_level`` of 60 [8]_.

Simulation of mb amplitude
~~~~~~~~~~~~~~~~~~~~~~~~~~
We simulate as WWSSN SP according to IASPEI [1]_. Poles and zeros used
are the same as specified by SeisComP [9]_ and IASPEI [1]_:

    - Poles: [-3.725 + -6.22j, -3.725 + 6.22j, -5.612 + 0j, -13.24 + 0j, -21.08 + 0j]
    - Zeros: [0 + 0j, 0 + 0j, 0 + 0j]
    - Gain: 532.14

The simulation is done using the same filtering and water level as used
for mla.

.. note::

    Again, unsure of this stuff. IASPEI once again specifie some
    extra terms that don't seem to be used, and don't specify gain,
    which SeisComP does. Also, what the hell is seismometer magnification?

Calculating the map
-------------------
We now have data stores for each channel containing 20 seconds of latency
measurements and traces simulated as the required seismometer for the
magnitude type.

.. note::
    
   If the number of samples in the 20 second window is less than
   the channel's sample rate * 20 seconds, then it's considered
   to not have enough data for caluclating on and is skipped. This
   could be refined, as it may be acceptable to calculate on partial
   data.

The first step is reducing the 20 second value stores for each channel
to an aggregate value (the "LTA" for that channel). 

Amplitude for mla
~~~~~~~~~~~~~~~~~
For mla amplitude, we convert the amplitude to millimeters and take
the average of the peak amplitudes of the trace. "Peak amplitude" here
means 1/2 the peak-to-trough amplitude, where peaks/troughs are separated
by a zero-crossing. 

.. figure:: _static/peaks.png
    :align: center

    A plot of the output of the peak finding algorithm. "Peak amplitude"
    is 1/2 of a peak + its adjacent trough.

This is based on [1]_:
amplitudes used are "one-half the maximum deflection of the seismogram trace,
peak-to-adjacent-trough or trough-to-adjacent-peak".
   
.. note::

    Another point of debate: what IASPEI means is to take the maximum
    of the peak amplitudes in the trace for use as `A` in magnitude
    formulas. In this case we're taking the peak amplitudes of the 
    entire 20 seconds and taking the average in an attempt to get an
    "average amplitude" over that time period. Would it make more
    sense to just take the maximum?

Amplitude for mb
~~~~~~~~~~~~~~~~
mb follows a similar process of measuring the average peak-to-peak,
but with some more steps. First the amplitudes are convered to 
micrometers (see :ref:`mb-attenuation`). The amplitude for the mb
formula is used as `A/T`; the amplitude over its period (to a maximum of
3 seconds) [1]_.

To achieve this, we use SeisComP's method [10]_. We want the peaks of `A/T`; 
the peaks must be calculated proportional to time, so we find the position
of the peaks in the derivative of the displacement trace, i.e. we are finding
the velocity peaks.

We then use these peak positions in the original displacement trace to get the
displacement amplitude where the peak `A/T` is located.

We again take 1/2 of each peak + its adjacent trough in the displacement trace.

We also record the period for each of these peak values, taken as
"twice the time-intervals separating the peak and adjacent-trough from which
the amplitudes are measured" [1]_. The formula for this is:

.. math::

    T = 2 * ((curr - prev) / sample rate)

Where `curr` is the position of the current peak/trough and `prev` is the position
of the previous peak/trough.
In other words,  we're calculating the number of samples between peak and trough and dividing this by
sample rate to get the period in seconds. This is again taken in the displacement trace,
but using the positions of the peak `A/T` found in its derivative.

When then divide each peak amplitude by its corresponding period and take the average of all these
values.

.. note::

    Same thing again regarding average vs maximum.

Calculating magnitude
~~~~~~~~~~~~~~~~~~~~~
Hopefully this has made sense so far: for every channel we are monitoring,
we now have a 20 second average of the peak amplitudes, calculated in the
nessecary way for use with its respective magnitude formula.

Now we turn this into a magnitude, and put it in a geospatial context
by associating it with a coordinate using attenuation.

For each station, we take the "best" 20 second average
amplitude of its channels - "best" being the lowest amplitude.
The logic here being that the channel with the "best" or least noisey signal
would be able to detect smaller events.

We then iterate through all coordinates (these are centers of our 
`resolution` x `resolution` grid cells). For each coordinate, we iterate
through the stations, sorted from closest to furthest (we prioritise
the closest stations). We calculate the magnitude the station could see at
this coordinate:

.. math::
   
    magnitude = log10(lta * snr) + attenuation

Where `lta` is the 20 second average amplitude, and `snr` is the 
signal-to-noise (SNR) ratio required for a detection. Currently the SNR
is set as 3. The rationale here is that for an event to be detected,
it would need to be `snr` times greater than the signal currently
observed by the station.

This probably gets as close as possible to the idea of detcap:
`We treat whatever signal currently seen by the station as noise. By
applying SNR to that signal, we can calculate the magnitude of a hypothetical
signal that would be detected despite that noise`.

Once we have calculated this value for `n` stations (the number of stations
required to detect an event reliably, e.g. 6 for mla), we take the `nth`
highest magnitude and set this as the detectable magnitude for that
coordinate. The logic being that this `nth` station is the weakest link
and we're unable to perform better than this station if `n` stations
are required.

If there aren't enough stations with valid data to fulfill the `n` 
stations requirement, the detectable magnitude is set as `nan` (we can't
detect anything at this coordinate).

Attenuation for mla
~~~~~~~~~~~~~~~~~~~
The attenuation formulas for mla are as follows:

Western Australia:

.. math::

    1.137 * log10(d) + (0.000657 * d) + 0.66

Eastern Australia:

.. math::

    1.34 * log10(d / 100.0) + 0.00055 * (d - 100.0) + 3.13

Southern Australia (Flinders Ranges):

.. math::

    1.1 * log10(d) + (0.0013 * d) + 0.7

Where `d` is the distance in degrees from the coordinate to the station.

At the start of processing, we check which region of the mla polygon
each coordinate of the map falls into. This determines which function
is used to calculate the attenuation for that coordinate.

Note that any coordinates outside the mla polygon are disregarded.

.. _mb-attenuation:

Attenuation for mb
~~~~~~~~~~~~~~~~~~
This applies the `q` attenuation value, based on the distance
from the station to the coordinate. I've made some assumptions on my
part, as there are multiple choices of `q` values:

- the original Richter-Gutenberg function, intended for use with amplitudes
  in micrometres, considered superceded.
- a version of Richter-Gutenberg intended for use with nanometres, as part
  of "The new IASPEI standards", accompanied by a -3 correction term.
  Used by NEIC.
- Veith-Clawson. I'm assuming intended for use with nanometres given it's
  lower values compared to factors intended for micrometres,
  but I was never able to confirm.
- SeisComP's, credited to Saul & Bormann 2007 [11]_.

Detcap uses SeisComp's method, with some assumptions. I believe these
`q` values have been calibrated for use with amplitudes in micrometers.
This is based on:

- SeisComP convering the amplitudes to micrometers before calculating
  mb [12]_.
- SeisComP's lack of -3 correction term, used with the NEIC method which
  is intended for use with nanometers.

What makes me wary about my assumptions is that Gempa states on the
SeisComP website [13]_ that mb amplitude is in micrometers, but they also
apply the -3 correction. This correction doesn't happen in their code.
When I use SeisComP's `q` and apply the -3 correction, the resulting
magnitudes seem too low (e.g. 4mb without correction will become ~1mb).
I'm chalking this up to a discrepancy between their code and documentation.

With these assumptions in mind, the SeisComP `q` table is used, and we
also use their code for interpolating inbetween the values [14]_.

Time-to-detection
~~~~~~~~~~~~~~~~~
Once we have the `n` stations used in calculating the magnitudes, we
take the avearge of the previously recorded latencies for each station
and add the AK-135 P-phase travel time from that station to the coordinate:

.. math::

    ttd = station\ latency + travel\ time

The worst (slowest) of these values amongst the `n` is then chosen as
the time-to-detection for the coordinate. The rationale being that
a signal must reach all `n` stations to be detected, so the fastest
we can detect the signal-generating event is limited by the slowest
station latency + travel time.

.. rubric:: Footnotes

.. [1] `IASPEI Working Group Recommendations <http://iaspei.org/commissions/commission-on-seismological-observation-and-interpretation/Summary_WG_recommendations_20130327.pdf>`_
.. [2] `Geoscience Australia mla SeisComP module <https://github.com/GeoscienceAustralia/ga-mla/blob/6d2b3fa5375bccf09a459bcac65426665bb7b826/plugins/magnitudes/mla/mla.cpp#L93>`_
.. [3] `SeisComP MLv amplitude processor <https://github.com/SeisComP/common/blob/master/libs/seiscomp/processing/amplitudes/MLv.cpp>`_
.. [4] `SeisComP ML amplitude processor <https://github.com/SeisComP/common/blob/447c13d0150e5965684bc36450b252a88b356213/libs/seiscomp/processing/amplitudes/ML.cpp#L140>`_
.. [5] `Wood-Anderson PAZ according to Obspy <https://github.com/obspy/obspy/blob/71cb8dfda4650935c244335af452eff4eb8db8b9/obspy/signal/invsim.py#L44>`_
.. [6] `Wood-Anderson PAZ according to SeisComP <https://github.com/SeisComP/common/blob/bb54cd5488636f7edac024ab18ff100a2dd0d21f/libs/seiscomp/math/filter/seismometers.cpp#L47>`_
.. [7] `Obspy's simulate_seismometer <https://docs.obspy.org/packages/autogen/obspy.signal.invsim.simulate_seismometer.html>`_
.. [8] `Note on water level <https://github.com/obspy/obspy/issues/1594#issuecomment-262232681>`_
.. [9] `WWSSN SP PAZ according to SeisComP <https://github.com/SeisComP/common/blob/bb54cd5488636f7edac024ab18ff100a2dd0d21f/libs/seiscomp/math/filter/seismometers.cpp#L392>`_
.. [10] `Finding A/T peaks <https://github.com/SeisComP/common/blob/5f7cd281fb2994fe782edc184f1e2343483aef36/libs/seiscomp/processing/amplitudes/mb.cpp#L176>`_
.. [11] `SeisComP's q table <https://github.com/SeisComP/common/blob/5f7cd281fb2994fe782edc184f1e2343483aef36/libs/seiscomp/seismology/mb.cpp#L57>`_
.. [12] `SeisComP convering to micrometers <https://github.com/SeisComP/common/blob/5f7cd281fb2994fe782edc184f1e2343483aef36/libs/seiscomp/processing/magnitudes/mb.cpp#L114>`_
.. [13] `SeisComP's published mb formula <https://www.seiscomp.de/doc/apps/global_mb.html>`_
.. [14] `SeisComP method for determining q <https://github.com/SeisComP/common/blob/5f7cd281fb2994fe782edc184f1e2343483aef36/libs/seiscomp/seismology/mb.cpp#L116>`_
